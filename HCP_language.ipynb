{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belhassen07/Ndevlopi/blob/master/HCP_language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The HCP dataset comprises task-based fMRI from a large sample of human subjects. The NMA-curated dataset includes time series data that has been preprocessed and spatially-downsampled by aggregating within 360 regions of interest.\n",
        "\n",
        "In order to use this dataset, please electronically sign the HCP data use terms at ConnectomeDB. Instructions for this are on pp. 24-25 of the HCP Reference Manual.\n",
        "\n",
        "In this notebook, NMA provides code for downloading the data and doing some basic visualisation and processing.\n",
        "\n",
        "For a detailed description of the tasks have a look pages 45-54 of the HCP reference manual."
      ],
      "metadata": {
        "id": "YWiKbDJV1SvQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b2LS-y8ya3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e795b5dd-602d-489e-d5d4-8d51c45ae8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install dependencies\n",
        "!pip install nilearn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gsRZbAWJzDqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Figure settings\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
      ],
      "metadata": {
        "id": "2YrxECrIzU0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Parameters"
      ],
      "metadata": {
        "id": "_31T218LMJlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data shared for NMA projects is a subset of the full HCP dataset\n",
        "N_SUBJECTS = 100\n",
        "\n",
        "# The data have already been aggregated into ROIs from the Glasser parcellation\n",
        "N_PARCELS = 360\n",
        "\n",
        "# The acquisition parameters for all tasks were identical\n",
        "TR = 0.72  # Time resolution, in seconds\n",
        "\n",
        "# The parcels are matched across hemispheres with the same order\n",
        "HEMIS = [\"Right\", \"Left\"]\n",
        "\n",
        "# Each experiment was repeated twice in each subject\n",
        "RUNS   = ['LR','RL']\n",
        "N_RUNS = 2"
      ],
      "metadata": {
        "id": "pG4kCkc6MPQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment Definitions"
      ],
      "metadata": {
        "id": "B5bxmiUzMSbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 7 tasks. Each has a number of 'conditions'\n",
        "# TIP: look inside the data folders for more fine-graned conditions\n",
        "\n",
        "EXPERIMENTS = {\n",
        "    'MOTOR'      : {'cond':['lf','rf','lh','rh','t','cue']},\n",
        "    'WM'         : {'cond':['0bk_body','0bk_faces','0bk_places','0bk_tools','2bk_body','2bk_faces','2bk_places','2bk_tools']},\n",
        "    'EMOTION'    : {'cond':['fear','neut']},\n",
        "    'GAMBLING'   : {'cond':['loss','win']},\n",
        "    'LANGUAGE'   : {'cond':['math','story']},\n",
        "    'RELATIONAL' : {'cond':['match','relation']},\n",
        "    'SOCIAL'     : {'cond':['ment','rnd']}\n",
        "}"
      ],
      "metadata": {
        "id": "IdidiIdR00Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading data"
      ],
      "metadata": {
        "id": "AQ9XiGXjMXoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading data file"
      ],
      "metadata": {
        "id": "szb0d-fS1imT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, requests\n",
        "\n",
        "fname = \"hcp_task.tgz\"\n",
        "url = \"https://osf.io/2y3fw/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ],
      "metadata": {
        "id": "JUvfM5ra1lcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract data"
      ],
      "metadata": {
        "id": "zBDYGeIcMlc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The download cells will store the data in nested directories starting here:\n",
        "HCP_DIR = \"./hcp_task\"\n",
        "\n",
        "# importing the \"tarfile\" module\n",
        "import tarfile\n",
        "\n",
        "# open file\n",
        "with tarfile.open(fname) as tfile:\n",
        "  # extracting file\n",
        "  tfile.extractall('.')\n",
        "\n",
        "subjects = np.loadtxt(os.path.join(HCP_DIR, 'subjects_list.txt'), dtype='str')"
      ],
      "metadata": {
        "id": "JxhpLHRo1s04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "fsR9nPSQ8D4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: load_single_timeseries"
      ],
      "metadata": {
        "id": "BcmvrdoZkSqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_single_timeseries(subject, experiment, run, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject and single run.\n",
        "\n",
        "  Args:\n",
        "    subject (str):      subject ID to load\n",
        "    experiment (str):   Name of experiment\n",
        "    run (int):          (0 or 1)\n",
        "    remove_mean (bool): If True, subtract the parcel-wise mean (typically the mean BOLD signal is not of interest)\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  bold_run  = RUNS[run]\n",
        "  bold_path = f\"{HCP_DIR}/subjects/{subject}/{experiment}/tfMRI_{experiment}_{bold_run}\"\n",
        "  bold_file = \"data.npy\"\n",
        "  ts = np.load(f\"{bold_path}/{bold_file}\")\n",
        "  if remove_mean:\n",
        "    ts -= ts.mean(axis=1, keepdims=True)\n",
        "  return ts"
      ],
      "metadata": {
        "id": "itS7VDd3kT_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: load_evs"
      ],
      "metadata": {
        "id": "99ehs1QekaCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_evs(subject, experiment, run, n_timepoints):\n",
        "    frames_list = []\n",
        "    task_key = f'tfMRI_{experiment}_{RUNS[run]}'\n",
        "\n",
        "    for cond in EXPERIMENTS[experiment]['cond']:\n",
        "        ev_file  = f\"{HCP_DIR}/subjects/{subject}/{experiment}/{task_key}/EVs/{cond}.txt\"\n",
        "        ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
        "        ev       = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
        "\n",
        "        start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
        "        duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
        "\n",
        "        frames = []\n",
        "        for s, d in zip(start, duration):\n",
        "            end = s + d\n",
        "            if s >= n_timepoints:\n",
        "                continue  # skip out-of-bounds trial\n",
        "            end = min(end, n_timepoints)\n",
        "            frames.append(np.arange(s, end))\n",
        "\n",
        "        frames_list.append(frames)\n",
        "    return frames_list"
      ],
      "metadata": {
        "id": "MibU0A26kbHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: average_frames"
      ],
      "metadata": {
        "id": "fYvvpG82khJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_frames(data, evs, experiment, cond):\n",
        "  idx = EXPERIMENTS[experiment]['cond'].index(cond)\n",
        "  return np.mean(np.concatenate([np.mean(data[:, evs[idx][i]], axis=1, keepdims=True) for i in range(len(evs[idx]))], axis=-1), axis=1)\n"
      ],
      "metadata": {
        "id": "PYYjWDGA2_0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate Language Data\n",
        "Code to concatenate language data (2 runs, 316 frames)"
      ],
      "metadata": {
        "id": "tzhVzlzbkkFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "MY_EXPERIMENT = {\n",
        "    'LANGUAGE'   : {'cond':['math','story']}\n",
        "}\n",
        "\n",
        "def concatenate_task_data():\n",
        "   \"\"\"\n",
        "   Concatenate data.npy files for all subjects for each task.\n",
        "   For each task, concatenate LR and RL runs for each subject, then stack across subjects.\n",
        "\n",
        "   Returns:\n",
        "       task_data (dict): Dictionary mapping task names to arrays of shape (n_subjects, n_parcels, n_timepoints_total)\n",
        "   \"\"\"\n",
        "\n",
        "   math_data = []\n",
        "   story_data = []\n",
        "   timepoints = 316\n",
        "\n",
        "   # Iterate through subjects\n",
        "   for subject in subjects:\n",
        "       subject_folder = Path(HCP_DIR) / \"subjects\" / subject\n",
        "       if not subject_folder.is_dir():\n",
        "           print(f\"Subject directory {subject_folder} does not exist. Skipping.\")\n",
        "           continue\n",
        "\n",
        "       # Iterate through tasks\n",
        "       for task in MY_EXPERIMENT:\n",
        "           task_folder = subject_folder / task\n",
        "           if not task_folder.is_dir():\n",
        "               print(f\"Task directory {task_folder} does not exist for subject {subject}. Skipping.\")\n",
        "               continue\n",
        "\n",
        "           # Load and concatenate LR and RL runs\n",
        "           #subject_task_data = []\n",
        "           math_activity_data = []\n",
        "           story_activity_data = []\n",
        "\n",
        "           for run_idx, run_suffix in enumerate(RUNS):\n",
        "               try:\n",
        "                   ts = load_single_timeseries(subject, task, run_idx, remove_mean=False)\n",
        "                   evs = load_evs(subject=subject, experiment=task, run=run_idx, n_timepoints=timepoints)\n",
        "\n",
        "\n",
        "                   idx_math = EXPERIMENTS[task]['cond'].index('math')\n",
        "                   math_activity = np.concatenate([np.mean(ts[:, evs[idx_math][i]], axis=1, keepdims=True) for i in range(len(evs[idx_math]))], axis=-1)\n",
        "                   #math_activity = average_frames(ts, evs, task, 'math')\n",
        "                   math_activity_data.append(math_activity)\n",
        "\n",
        "                   idx_story = EXPERIMENTS[task]['cond'].index('story')\n",
        "                   story_activity = np.concatenate([np.mean(ts[:, evs[idx_story][i]], axis=1, keepdims=True) for i in range(len(evs[idx_story]))], axis=-1)\n",
        "                   #story_activity = average_frames(ts, evs, task, 'story')\n",
        "                   story_activity_data.append(story_activity)\n",
        "\n",
        "                   #subject_task_data.append(ts)\n",
        "\n",
        "               except Exception as e:\n",
        "                   print(f\"Error loading data.npy for {subject}/{task}/tfMRI_{task}_{run_suffix}: {e}\")\n",
        "                   #subject_task_data.append(None)\n",
        "                   math_activity_data.append(None)\n",
        "                   story_activity_data.append(None)\n",
        "\n",
        "           # Check if any run failed to load\n",
        "           if any(x is None for x in math_activity_data):\n",
        "               print(f\"Skipping subject {subject} for task {task} due to missing run data.\")\n",
        "               continue\n",
        "\n",
        "           if any(x is None for x in story_activity_data):\n",
        "               print(f\"Skipping subject {subject} for task {task} due to missing run data.\")\n",
        "               continue\n",
        "\n",
        "           # Concatenate LR and RL runs along the time axis (axis=1)\n",
        "           try:\n",
        "               #concatenated_ts = np.concatenate(subject_task_data, axis=1)\n",
        "               #task_data[task].append(concatenated_ts)\n",
        "                concatenated_math_data = np.concatenate(math_activity_data, axis=1)\n",
        "                concatenated_story_data = np.concatenate(story_activity_data, axis=1)\n",
        "\n",
        "                math_data.append(concatenated_math_data)\n",
        "                story_data.append(concatenated_story_data)\n",
        "           except Exception as e:\n",
        "               print(f\"Error concatenating runs for {subject}/{task}: {e}\")\n",
        "               continue\n",
        "\n",
        "   math_stack = np.stack(math_data, axis=0)  # (n_subjects, n_parcels, n_timepoints)\n",
        "   story_stack = np.stack(story_data, axis=0)\n",
        "\n",
        "   print(math_stack)\n",
        "   print(story_stack)\n",
        "\n",
        "   result = np.vstack([math_stack, story_stack])\n",
        "   return result\n",
        "\n",
        "result = concatenate_task_data()\n",
        "print(result)"
      ],
      "metadata": {
        "id": "CeqgZxe3HDOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "ecc5b1db-fa2c-4116-eb8e-8319938e9d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all input arrays must have the same shape",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-4087068686.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate_task_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-11-4087068686.py\u001b[0m in \u001b[0;36mconcatenate_task_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m                \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m    \u001b[0mmath_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (n_subjects, n_parcels, n_timepoints)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m    \u001b[0mstory_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Designe matrix options:\n",
        "(200, 360, 316) -- subjects x condition, ROIs, frames\n",
        "(1600, 360, ?) -- subjects x block, ROIs, frames\n",
        "(200, 360, 1) -- subjects x concition, ROIs, average frame"
      ],
      "metadata": {
        "id": "L852yXal4xwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Investigating the Dataset\n",
        "Investigating data set (JW)\n",
        "\n",
        "\n",
        "* keep in mind that indices for ROIs now are based on the network and index 1 is a different ROI based on what network you are in\n",
        "* For exploration/ definition of ROI in the bigger context of our project stick to the indices in the whole data set [0-359]!!!\n",
        "\n"
      ],
      "metadata": {
        "id": "HHI4cM6mxZrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regions = np.load(f\"{HCP_DIR}/regions.npy\").T\n",
        "region_info = dict(\n",
        "    name=regions[0].tolist(),\n",
        "    network=regions[1],\n",
        "    hemi=['Right']*int(N_PARCELS/2) + ['Left']*int(N_PARCELS/2),\n",
        ")"
      ],
      "metadata": {
        "id": "hFQorVmUxZHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List regions included (Joshua)"
      ],
      "metadata": {
        "id": "MPKT-XROk2bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region_names = region_info['name']\n",
        "\n",
        "for i, name in enumerate(region_names):\n",
        "    print(f\"{i:3d}: {name}\")\n"
      ],
      "metadata": {
        "id": "ohEKPW5oxqdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sort regions by network (Joshua)\n",
        "regions split by network (JW)\n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item"
      ],
      "metadata": {
        "id": "xOPgraYHk6cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Group regions by network\n",
        "networks = defaultdict(list)\n",
        "for name, net in zip(region_info['name'], region_info['network']):\n",
        "    networks[net].append(name)\n",
        "\n",
        "# Print all networks and their associated parcels\n",
        "for network_name in sorted(networks.keys()):\n",
        "    print(f\"\\n {network_name} ({len(networks[network_name])} parcels):\")\n",
        "    for i, parcel in enumerate(networks[network_name]):\n",
        "        print(f\"  {i+1:2d}. {parcel}\")"
      ],
      "metadata": {
        "id": "7qmieJ_Jx49L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading subject info\n",
        "loading experiment and subject as before"
      ],
      "metadata": {
        "id": "yPMdyRTAlCpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_exp = 'LANGUAGE'\n",
        "my_subj = subjects[1]\n",
        "my_run = 1\n",
        "\n",
        "data = load_single_timeseries(subject=my_subj,\n",
        "                              experiment=my_exp,\n",
        "                              run=my_run,\n",
        "                              remove_mean=True)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "fYLngvrS0TuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Amount of Trials per run per Subject (Joshua)\n",
        "investigate amount of trials per run per subject (JW)\n",
        "\n",
        "\n",
        "*   probably not most efficient way though"
      ],
      "metadata": {
        "id": "GZbtawjglK8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "\n",
        "for s in subjects:\n",
        "    for r, run_name in zip([0, 1], ['LR', 'RL']):\n",
        "        try:\n",
        "            data = load_single_timeseries(subject=s, experiment=my_exp, run=r, remove_mean=True)\n",
        "            evs = load_evs(subject=s, experiment=my_exp, run=r, n_timepoints=data.shape[1])\n",
        "\n",
        "            if not isinstance(evs, list) or not all(isinstance(x, list) for x in evs):\n",
        "                raise ValueError(f\"EVS returned in wrong format: {type(evs)}\")\n",
        "\n",
        "            row = {\n",
        "                'subject': s,\n",
        "                'run': run_name,\n",
        "                'math': len(evs[0]),\n",
        "                'story': len(evs[1])\n",
        "            }\n",
        "\n",
        "            rows.append(row)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error for subject {s}, run {r}: {e}\")\n",
        "\n",
        "df_trials_runs = pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "lIImEZQi0Ikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_melted = pd.melt(\n",
        "    df_trials_runs,\n",
        "    id_vars=['subject', 'run'],\n",
        "    value_vars=['math', 'story'],\n",
        "    var_name='condition',\n",
        "    value_name='n_trials'\n",
        ")\n",
        "\n",
        "# Clean up labels\n",
        "df_melted['condition'] = df_melted['condition'].replace({\n",
        "    'cond_0_trials': 'math',\n",
        "    'cond_1_trials': 'story'\n",
        "})\n"
      ],
      "metadata": {
        "id": "8CagCcRB0EQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivoted = df_trials_runs.pivot(index='subject', columns='run', values=['math', 'story'])\n",
        "\n",
        "df_pivoted.columns = [f\"{run} {cond}\" for cond, run in df_pivoted.columns]\n",
        "\n",
        "df_pivoted.reset_index(inplace=True)\n",
        "\n",
        "print(df_pivoted.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "7Iuahof0y9hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update Design Matrix\n",
        "Code update design matrix (JW):"
      ],
      "metadata": {
        "id": "nQh_zf5jnyny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conditions = ['math', 'story']\n",
        "n_rois = 360\n",
        "rows = [] # stores the BOLD vectors\n",
        "meta = [] # information about subject, trial, run, condition, ...\n",
        "\n",
        "for s in subjects:\n",
        "    for r, run_name in zip([0, 1], ['LR', 'RL']): # Loops over all subjects (s) in the list 'subjects' for both executions of experiment (LR & RL)\n",
        "        try:\n",
        "            data = load_single_timeseries(subject=s, experiment=my_exp, run=r, remove_mean=True) # loading timeseries data for a single subject and run (1 row per ROI, 1 column per TR)\n",
        "            evs = load_evs(subject=s, experiment=my_exp, run=r, n_timepoints=data.shape[1]) # loading evs files/ information about condition, trials, frame indices\n",
        "\n",
        "            for cond_idx, cond_name in enumerate(conditions):\n",
        "                for trial_idx, trial_frames in enumerate(evs[cond_idx]): # for each condition gets TR (trials frames) related to that condition\n",
        "                    # Average BOLD signal across time points (TRs) for each ROI in this trial\n",
        "                    trial_bold = data[:, trial_frames].mean(axis=1)  # [shape (360,)]\n",
        "                    rows.append(trial_bold)\n",
        "                    meta.append({\n",
        "                        'subject': s,\n",
        "                        'run': run_name,\n",
        "                        'condition': cond_name,\n",
        "                        'trial': trial_idx\n",
        "                    })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping subject {s}, run {r}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Create final DataFrame\n",
        "df_trials = pd.DataFrame(rows, columns=[f\"ROI_{i}\" for i in range(n_rois)])\n",
        "df_meta = pd.DataFrame(meta)\n",
        "\n",
        "df_all = pd.concat([df_meta, df_trials], axis=1)"
      ],
      "metadata": {
        "id": "WDqwSG-SpxEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_all)"
      ],
      "metadata": {
        "id": "rvkQ4ogRqK4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_trials)"
      ],
      "metadata": {
        "id": "Hi9d6GVRqQ0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_meta)"
      ],
      "metadata": {
        "id": "CS1tow1tqT_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display mean BOLD activity for a selected region (Joshua)"
      ],
      "metadata": {
        "id": "RQFdvgfpO9VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region_idx = 165 # this is R_pOFC\n",
        "region_ts = data[region_idx]\n",
        "\n",
        "\n",
        "def get_safe_indices(trials, max_len):\n",
        "   flat = np.concatenate(trials)\n",
        "   return flat[flat < max_len]\n",
        "\n",
        "\n",
        "math_idxs = get_safe_indices(evs[0], len(region_ts))\n",
        "story_idxs = get_safe_indices(evs[1], len(region_ts))\n",
        "\n",
        "\n",
        "math_vals = np.mean(region_ts[math_idxs])\n",
        "story_vals = np.mean(region_ts[story_idxs])\n",
        "\n",
        "\n",
        "plt.bar(['Math', 'Story'], [math_vals, story_vals], color=['steelblue', 'orange'])\n",
        "plt.ylabel('Mean BOLD signal')\n",
        "plt.title(f'Region {region_idx}: Math vs Story')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wV8apMj5PCNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression"
      ],
      "metadata": {
        "id": "O5Usx99JjQrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def model_selection(X, y, C_values):\n",
        "  \"\"\"Compute CV accuracy for each C value.\n",
        "  Args:\n",
        "    X (2D array): Data matrix\n",
        "    y (1D array): Label vector\n",
        "    C_values (1D array): Array of hyperparameter values.\n",
        "  Returns:\n",
        "    accuracies (1D array): CV accuracy with each value of C.\n",
        "  \"\"\"\n",
        "  accuracies = []\n",
        "  for C in C_values:\n",
        "    # Initialize and fit the model\n",
        "    # (Hint, you may need to set max_iter)\n",
        "    model = LogisticRegression(penalty=\"l2\", C=C, max_iter=10000)\n",
        "    # Get the accuracy for each test split using cross-validation\n",
        "    accs = cross_val_score(model, X, y, cv=8)\n",
        "    # Store the average test accuracy for this value of C\n",
        "    accuracies.append(accs.mean())\n",
        "  index= np.argmax(accuracies)\n",
        "  C_max = C_values[index]\n",
        "  model = LogisticRegression(penalty=\"l2\", C=C_max, max_iter=10000)\n",
        "  model.fit(X,y)\n",
        "  return model, C_max\n",
        "\n",
        "\n",
        "df_trials = pd.DataFrame(rows, columns=[f\"ROI_{i}\" for i in range(n_rois)])\n",
        "df_meta = pd.DataFrame(meta)\n",
        "\n",
        "X = df_trials\n",
        "y = df_meta[\"condition\"].map({\"math\": 0, \"story\": 1}).values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "C_values = np.logspace(-4, 4, 9)\n",
        "\n",
        "log_model, C_max = model_selection(X_train, y_train, C_values)"
      ],
      "metadata": {
        "id": "IvCct42RjSTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = log_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "train_preds = log_model.predict(X_train)\n",
        "train_acc = accuracy_score(y_train, train_preds)\n",
        "print(train_acc)"
      ],
      "metadata": {
        "id": "SF6PwD8pnM3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cm1 = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', xticklabels=['math', 'story'], yticklabels=['math', 'story'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "\n",
        "print(classification_report(y_train, train_preds))"
      ],
      "metadata": {
        "id": "LlGL92hFp09c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}